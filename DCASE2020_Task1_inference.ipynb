{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from DCASE_plots import plot_confusion_matrix\n",
    "\n",
    "import librosa\n",
    "import soundfile as sound\n",
    "import keras\n",
    "import tensorflow\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"Pysoundfile version = \",sound.__version__)\n",
    "print(\"keras version = \",keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WhichTask = '1a'\n",
    "model_dir = 'XXXXXXXXX_1a_DEV_310/'\n",
    "model_path = model_dir + 'model.h5'\n",
    "\n",
    "focal_loss = True\n",
    "gamma=1.0\n",
    "alpha=0.3\n",
    "domain_aux = False\n",
    "\n",
    "###############################\n",
    "\n",
    "assert((domain_aux and focal_loss) == False)\n",
    "\n",
    "if WhichTask =='1a':\n",
    "\n",
    "    ThisPath = '../../commonData/dcase2020/TAU-urban-acoustic-scenes-2020-mobile-development/'\n",
    "    File = ThisPath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "    sr = 44100\n",
    "    num_audio_channels = 1 \n",
    "\n",
    "    scene_map_str = \"\"\"\n",
    "    airport 0 \n",
    "    bus 1\n",
    "    metro 2\n",
    "    metro_station 3\n",
    "    park 4\n",
    "    public_square 5\n",
    "    shopping_mall 6\n",
    "    street_pedestrian 7\n",
    "    street_traffic 8\n",
    "    tram 9\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "elif WhichTask =='1b':\n",
    "   \n",
    "    ThisPath = '../../commonData/dcase2020/TAU-urban-acoustic-scenes-2020-3class-development/'\n",
    "    File = ThisPath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "    num_audio_channels = 2    \n",
    "    sr = 48000\n",
    "\n",
    "    scene_map_str = \"\"\"\n",
    "    indoor 0 \n",
    "    outdoor 1\n",
    "    transportation 2\n",
    "    \"\"\"    \n",
    "\n",
    "\n",
    "SampleDuration = 10\n",
    "NumFreqBins = 128\n",
    "NumFFTPoints = 2048\n",
    "HopLength = int(NumFFTPoints/2)\n",
    "NumTimeBins = int(np.ceil(SampleDuration*sr/float(HopLength)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load filenames and labels\n",
    "dev_test_df = pd.read_csv(File,sep='\\t', encoding='ASCII')\n",
    "wavpaths_val = dev_test_df['filename'].tolist()\n",
    "\n",
    "\n",
    "ClassNames = np.unique(dev_test_df['scene_label'])\n",
    "print ClassNames\n",
    "y_val_labels =  dev_test_df['scene_label'].astype('category').cat.codes.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load wav files and get log-mel spectrograms, deltas, and delta-deltas\n",
    "def deltas(X_in):\n",
    "    X_out = (X_in[:,:,2:,:]-X_in[:,:,:-2,:])/10.0\n",
    "    X_out = X_out[:,:,1:-1,:]+(X_in[:,:,4:,:]-X_in[:,:,:-4,:])/5.0\n",
    "    return X_out\n",
    "\n",
    "LM_val = np.zeros((len(wavpaths_val),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
    "for i in range(len(wavpaths_val)):\n",
    "    sig,fs = sound.read(ThisPath + wavpaths_val[i],stop=SampleDuration*sr)\n",
    "    for channel in range(num_audio_channels):\n",
    "        if len(sig.shape)==1:\n",
    "            sig = np.expand_dims(sig,-1)\n",
    "        LM_val[i,:,:,channel]= librosa.feature.melspectrogram(sig[:,channel], \n",
    "                                       sr=sr,\n",
    "                                       n_fft=NumFFTPoints,\n",
    "                                       hop_length=HopLength,\n",
    "                                       n_mels=NumFreqBins,\n",
    "                                       fmin=0.0,\n",
    "                                       fmax=sr/2,\n",
    "                                       htk=True,\n",
    "                                       norm=None)\n",
    "    if i%700 == 699:\n",
    "        print \"%i/%i val samples done\" % (i+1, len(wavpaths_val))\n",
    "print \"Done\" \n",
    "\n",
    "LM_val=np.log(LM_val+1e-8)\n",
    "LM_deltas_val = deltas(LM_val)\n",
    "LM_deltas_deltas_val = deltas(LM_deltas_val)\n",
    "LM_val = np.concatenate((LM_val[:,:,4:-4,:],LM_deltas_val[:,:,2:-2,:],LM_deltas_deltas_val),axis=-1)\n",
    "\n",
    "print ('data dimension: ', LM_val.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and run the model\n",
    "try:\n",
    "    os.makedirs('plots/')\n",
    "except OSError:\n",
    "    if not os.path.isdir('plots/'):\n",
    "        raise\n",
    "png_name = 'plots/official_fold_task' + WhichTask + '_' + model_dir[:-1] + '.png'\n",
    "savename = 'plots/official_fold_task' + WhichTask + '_' + model_dir[:-1] + '.output.csv'\n",
    "        \n",
    "\n",
    "if focal_loss:\n",
    "\n",
    "    from DCASE_training_functions import categorical_focal_loss\n",
    "    best_model = keras.models.load_model(model_path, \n",
    "                                         custom_objects={'categorical_focal_loss_fixed': categorical_focal_loss(gamma=gamma, alpha=alpha)})\n",
    "    softmax = best_model.predict(LM_val)\n",
    "\n",
    "else:\n",
    "\n",
    "    if domain_aux:\n",
    "\n",
    "        best_model = keras.models.load_model(model_path)\n",
    "        from keras.models import Model\n",
    "\n",
    "        exclude_da = Model(inputs = best_model.input, outputs = best_model.get_layer('activation_35').output)\n",
    "        softmax = exclude_da.predict(LM_val)\n",
    "\n",
    "    else:\n",
    "\n",
    "        best_model = keras.models.load_model(model_path)\n",
    "        softmax = best_model.predict(LM_val)\n",
    "\n",
    "print (type(softmax))\n",
    "y_pred_val = np.argmax(softmax,axis=1)\n",
    "\n",
    "\n",
    "#get metrics\n",
    "Overall_accuracy = np.sum(y_pred_val==y_val_labels)/float(LM_val.shape[0])\n",
    "print(\"overall accuracy: \", Overall_accuracy)\n",
    "\n",
    "plot_confusion_matrix(y_val_labels, y_pred_val, ClassNames,normalize=True,title=None, png_name=png_name)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_val_labels,y_pred_val)\n",
    "conf_mat_norm_recall = conf_matrix.astype('float32')/conf_matrix.sum(axis=1)[:,np.newaxis]\n",
    "conf_mat_norm_precision = conf_matrix.astype('float32')/conf_matrix.sum(axis=0)[:,np.newaxis]\n",
    "recall_by_class = np.diagonal(conf_mat_norm_recall)\n",
    "precision_by_class = np.diagonal(conf_mat_norm_precision)\n",
    "mean_recall = np.mean(recall_by_class)\n",
    "mean_precision = np.mean(precision_by_class)\n",
    "\n",
    "print(\"per-class accuracy (recall): \",recall_by_class)\n",
    "print(\"per-class precision: \",precision_by_class)\n",
    "print(\"mean per-class recall: \",mean_recall)\n",
    "print(\"mean per-class precision: \",mean_precision)\n",
    "    \n",
    "    \n",
    "# create output.csv\n",
    "scene_index_map={}\n",
    "for line in scene_map_str.strip().split('\\n'):\n",
    "    ch, index = line.split()\n",
    "    scene_index_map[int(index)] = ch\n",
    "\n",
    "labels = [str(scene_index_map[c]) for c in y_pred_val]\n",
    "filename = [a[6:] for a in wavpaths_val]\n",
    "\n",
    "left = {'filename': filename,\n",
    "        'scene_label': labels\n",
    "}\n",
    "\n",
    "left_df = pd.DataFrame(left)\n",
    "if WhichTask =='1a':\n",
    "    right_df = pd.DataFrame(softmax, columns = ['airport','bus','metro','metro_station','park','public_square','shopping_mall','street_pedestrian','street_traffic','tram'])\n",
    "elif WhichTask =='1b':\n",
    "    right_df = pd.DataFrame(softmax, columns = ['indoor','outdoor','transportation'])\n",
    "\n",
    "merge = pd.concat([left_df, right_df], axis=1, sort=False)\n",
    "merge.to_csv(savename, sep = '\\t', index=False) \n",
    "\n",
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
