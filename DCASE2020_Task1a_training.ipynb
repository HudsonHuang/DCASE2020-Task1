{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"8,9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sound\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.utils import multi_gpu_model, to_categorical\n",
    "\n",
    "import sys, subprocess\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "\n",
    "from DCASE_training_functions import LR_WarmRestart,MixupGenerator, categorical_focal_loss, ckpt\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"Pysoundfile version = \",sound.__version__)\n",
    "print(\"keras version = \",keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WhichTask = '1a'\n",
    "MODE = 'DEV'    # 'DEV' uses the official data fold; 'VAL' uses all data in development set for training\n",
    "\n",
    "\n",
    "if WhichTask =='1a':\n",
    "    ThisPath = '../../commonData/dcase2020/TAU-urban-acoustic-scenes-2020-mobile-development/'\n",
    "    num_audio_channels = 1    \n",
    "    sr = 44100\n",
    "    \n",
    "    if MODE == 'DEV':\n",
    "        TrainFile = ThisPath + 'evaluation_setup/fold1_train_st.csv'\n",
    "        ValFile = ThisPath + 'evaluation_setup/fold1_evaluate_st.csv'\n",
    "\n",
    "    elif MODE == 'VAL':\n",
    "        TrainFile = ThisPath + '/meta_st.csv'\n",
    "\n",
    "    \n",
    "SampleDuration = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log-mel spectrogram parameters\n",
    "NumFreqBins = 128\n",
    "NumFFTPoints = 2048\n",
    "HopLength = int(NumFFTPoints/2)\n",
    "NumTimeBins = int(np.ceil(SampleDuration*sr/float(HopLength)))\n",
    "\n",
    "multi_gpus = 2    # the number of GPUs used for training \n",
    "model_selection = 1\n",
    "'''\n",
    "0) ResNet with no freq split\n",
    "1) ResNet with freq split (domain adaptation is not supported)\n",
    "'''\n",
    "\n",
    "#training parameters\n",
    "max_lr = 0.1\n",
    "batch_size = 32/multi_gpus\n",
    "num_epochs = 310\n",
    "mixup_alpha = 0.4\n",
    "crop_length = 400 # \n",
    "delta = True\n",
    "num_filters = 28\n",
    "output_num_filters_factor = 1\n",
    "wd = 1e-3\n",
    "\n",
    "num_stacks = 4    # number of residual stacks \n",
    "stacking_frames = None # put None if not applied\n",
    "\n",
    "\n",
    "'''\n",
    "Applying domain adaptation OR using focal loss function\n",
    "(Set TRUE for both flags is not supported)\n",
    "'''\n",
    "\n",
    "domain_aux = False     # whether to add an auxiliary classifier to apply mild domain adaptation\n",
    "beta = 0.1            # apply weighting to this new loss\n",
    "\n",
    "focal_loss = True    # whether to use focal loss\n",
    "gamma=1.0\n",
    "alpha=0.3\n",
    "\n",
    "TEST = 1    #use 1/n data to verify the model before training; put 1 if not applied\n",
    "\n",
    "assert((domain_aux and focal_loss) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load filenames and labels\n",
    "dev_train_df = pd.read_csv(TrainFile,sep='\\t', encoding='ASCII')\n",
    "wavpaths_train = dev_train_df['filename'].tolist()\n",
    "y_train_labels =  dev_train_df['scene_label'].astype('category').cat.codes.values\n",
    "\n",
    "ClassNames = np.unique(dev_train_df['scene_label'])\n",
    "NumClasses = len(ClassNames)\n",
    "y_train = keras.utils.to_categorical(y_train_labels, NumClasses)\n",
    "\n",
    "if MODE == 'DEV':\n",
    "    dev_val_df = pd.read_csv(ValFile,sep='\\t', encoding='ASCII')\n",
    "    wavpaths_val = dev_val_df['filename'].tolist()\n",
    "    y_val_labels =  dev_val_df['scene_label'].astype('category').cat.codes.values\n",
    "    y_val = keras.utils.to_categorical(y_val_labels, NumClasses)\n",
    "\n",
    "if domain_aux:\n",
    "    y_train_domain_labels =  dev_train_df['source_label'].astype('category').cat.codes.values\n",
    "    y_train_domain = keras.utils.to_categorical(y_train_domain_labels, 2)\n",
    "    if MODE == 'DEV':\n",
    "        y_val_domain_labels =  dev_val_df['source_label'].astype('category').cat.codes.values\n",
    "        y_val_domain = keras.utils.to_categorical(y_val_domain_labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load wav files and get log-mel spectrograms, deltas, and delta-deltas\n",
    "def deltas(X_in):\n",
    "    X_out = (X_in[:,:,2:,:]-X_in[:,:,:-2,:])/10.0\n",
    "    X_out = X_out[:,:,1:-1,:]+(X_in[:,:,4:,:]-X_in[:,:,:-4,:])/5.0\n",
    "    return X_out\n",
    "\n",
    "if TEST>1 and MODE == 'DEV':\n",
    "    train_size = int(len(wavpaths_train)/TEST)\n",
    "    train_idx = np.random.choice(range(len(wavpaths_train)), int(len(wavpaths_train)/TEST), replace=False)\n",
    "    val_idx = np.random.choice(range(len(wavpaths_val)), int(train_size/4), replace=False)\n",
    "    \n",
    "    wavpaths_train = np.array(wavpaths_train)[train_idx]\n",
    "    wavpaths_val = np.array(wavpaths_val)[val_idx]\n",
    "    y_train = y_train[train_idx]\n",
    "    y_val = y_val[val_idx]\n",
    "    num_epochs = 30\n",
    "    \n",
    "    if domain_aux:\n",
    "        y_train_domain = y_train_domain[train_idx]\n",
    "        y_val_domain = y_val_domain[val_idx]\n",
    "\n",
    "\n",
    "LM_train = np.zeros((len(wavpaths_train),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
    "for i in range(len(wavpaths_train)):\n",
    "    sig,fs = sound.read(ThisPath + wavpaths_train[i],stop=SampleDuration*sr)\n",
    "   # print (sig.shape, fs)\n",
    "    \n",
    "    for channel in range(num_audio_channels):\n",
    "        if len(sig.shape)==1:\n",
    "            sig = np.expand_dims(sig,-1)\n",
    "        LM_train[i,:,:,channel] = librosa.feature.melspectrogram(sig[:,channel], \n",
    "                               sr=sr,\n",
    "                               n_fft=NumFFTPoints,\n",
    "                               hop_length=HopLength,\n",
    "                               n_mels=NumFreqBins,\n",
    "                               fmin=0.0,\n",
    "                               fmax=sr/2,\n",
    "                               htk=True,\n",
    "                               norm=None)  \n",
    "        \n",
    "    if i%1500 == 1499:\n",
    "        print \"%i/%i training samples done\" % (i+1, len(wavpaths_train))\n",
    "print \"Done\"\n",
    "\n",
    "\n",
    "LM_train = np.log(LM_train+1e-8)\n",
    "\n",
    "if delta:\n",
    "    LM_deltas_train = deltas(LM_train)\n",
    "    LM_deltas_deltas_train = deltas(LM_deltas_train)\n",
    "    LM_train = np.concatenate((LM_train[:,:,4:-4,:],LM_deltas_train[:,:,2:-2,:],LM_deltas_deltas_train),axis=-1)\n",
    "\n",
    "if MODE == 'DEV':\n",
    "    \n",
    "    LM_val = np.zeros((len(wavpaths_val),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
    "    for i in range(len(wavpaths_val)):\n",
    "        sig,fs = sound.read(ThisPath + wavpaths_val[i],stop=SampleDuration*sr)\n",
    "        for channel in range(num_audio_channels):\n",
    "            if len(sig.shape)==1:\n",
    "                sig = np.expand_dims(sig,-1)\n",
    "            LM_val[i,:,:,channel]= librosa.feature.melspectrogram(sig[:,channel], \n",
    "                                           sr=sr,\n",
    "                                           n_fft=NumFFTPoints,\n",
    "                                           hop_length=HopLength,\n",
    "                                           n_mels=NumFreqBins,\n",
    "                                           fmin=0.0,\n",
    "                                           fmax=sr/2,\n",
    "                                           htk=True,\n",
    "                                           norm=None)\n",
    "        if i%700 == 699:\n",
    "            print \"%i/%i val samples done\" % (i+1, len(wavpaths_val))\n",
    "    print \"Done\" \n",
    "    LM_val = np.log(LM_val+1e-8)\n",
    "    if delta: \n",
    "        LM_deltas_val = deltas(LM_val)\n",
    "        LM_deltas_deltas_val = deltas(LM_deltas_val)\n",
    "        LM_val = np.concatenate((LM_val[:,:,4:-4,:],LM_deltas_val[:,:,2:-2,:],LM_deltas_deltas_val),axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "    if model_selection == 2:\n",
    "        pre_padding_length = LM_val.shape[2] # padding may be required\n",
    "\n",
    "        if np.mod(pre_padding_length,8) != 0:\n",
    "            pad_size = 8-np.mod(pre_padding_length,8)\n",
    "            temp  = np.tile(LM_val[:,:,-1,:],pad_size)\n",
    "            temp = np.reshape(temp,(LM_val.shape[0],LM_val.shape[1],-1,LM_val.shape[-1]))\n",
    "            LM_val = np.concatenate((LM_val,temp),axis=2)\n",
    "            \n",
    "if delta:\n",
    "    num_audio_channels *= 3\n",
    "\n",
    "\n",
    "print ('training data dimension: ', LM_train.shape)\n",
    "if MODE == 'DEV':\n",
    "    print ('validation data dimension: ', LM_val.shape) \n",
    "    \n",
    "print ('training labels dimension: ', y_train.shape)\n",
    "if MODE == 'DEV':\n",
    "    print ('validation labels dimension: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = datetime.datetime.now().strftime('%y%m%d%H%M')\n",
    "tag = stamp + '_' + WhichTask + '_' + MODE + '_'+ str(num_epochs)\n",
    "savedir = os.path.join(os.getcwd(), tag)\n",
    "print \"Model path: %s\" % savedir\n",
    "try:\n",
    "    os.makedirs(savedir)\n",
    "except OSError:\n",
    "    if not os.path.isdir(savedir):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and compile the model\n",
    "\n",
    "subprocess.check_call([\"cp\", \"DCASE2020_ResNet.py\", savedir])\n",
    "\n",
    "if model_selection == 0: #resnet with no split\n",
    "    \n",
    "    from DCASE2020_ResNet import model_resnet_no_split\n",
    "    model = model_resnet_no_split(NumClasses,\n",
    "                         input_shape =[NumFreqBins,None,num_audio_channels], \n",
    "                         num_filters = num_filters,\n",
    "                         wd=wd,\n",
    "                         num_stacks = num_stacks,\n",
    "                         output_num_filters_factor = output_num_filters_factor)  \n",
    "    \n",
    "elif model_selection == 1: #resnet with split\n",
    "    \n",
    "    from DCASE2020_ResNet import model_resnet    \n",
    "    model = model_resnet(NumClasses,\n",
    "                         input_shape =[NumFreqBins,None,num_audio_channels], \n",
    "                         num_filters = num_filters,\n",
    "                         wd=wd,\n",
    "                         num_stacks = num_stacks,\n",
    "                         output_num_filters_factor = output_num_filters_factor,\n",
    "                         stacking_frames = stacking_frames,\n",
    "                         domain_aux = domain_aux)    \n",
    "\n",
    "    \n",
    "    \n",
    "model.summary()\n",
    "if multi_gpus > 1:\n",
    "    model = multi_gpu_model(model,gpus=multi_gpus)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "if domain_aux:\n",
    "    model.compile(loss=['categorical_crossentropy','binary_crossentropy'],\n",
    "          loss_weights=[1-beta, beta],\n",
    "          optimizer =SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "else:\n",
    "\n",
    "    if focal_loss:\n",
    "        model.compile(loss=[categorical_focal_loss(gamma=gamma, alpha=alpha)],\n",
    "              optimizer =SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])        \n",
    "    else:\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer =SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set learning rate schedule\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(LM_train.shape[0]/batch_size), Tmult=2, T0 = 10,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [11.0, 31.0, 71.0, 151.0, 311.0, 631.0]) \n",
    "\n",
    "log_path = savedir + \"/log.csv\"\n",
    "log_cb = CSVLogger(log_path)\n",
    "\n",
    "ckpt_path=savedir+'/model-{epoch:02d}.h5'\n",
    "ckpt = ckpt(filepath=ckpt_path, ckpts=[2, 70, 150]) \n",
    "\n",
    "callbacks = [lr_scheduler,log_cb,ckpt]\n",
    "\n",
    "\n",
    "#create data generator\n",
    "if domain_aux:\n",
    "    TrainDataGen = MixupGenerator(LM_train, \n",
    "                                  y_train, \n",
    "                                  batch_size=batch_size,\n",
    "                                  alpha=mixup_alpha,\n",
    "                                  crop_length=crop_length,\n",
    "                                  y_train_2 = y_train_domain)()\n",
    "    \n",
    "    \n",
    "    #train the model\n",
    "    if MODE == 'DEV':\n",
    "        history = model.fit_generator(TrainDataGen,\n",
    "                                      validation_data=(LM_val, [y_val, y_val_domain]),\n",
    "                                      epochs=num_epochs, \n",
    "                                      verbose=1, \n",
    "                                      workers=4,\n",
    "                                      max_queue_size = 100,\n",
    "                                      callbacks=callbacks,\n",
    "                                      steps_per_epoch=np.ceil(LM_train.shape[0]/batch_size)\n",
    "                                      )     \n",
    "    elif MODE == 'VAL':\n",
    "        history = model.fit_generator(TrainDataGen,\n",
    "                                      epochs=num_epochs, \n",
    "                                      verbose=1, \n",
    "                                      workers=4,\n",
    "                                      max_queue_size = 100,\n",
    "                                      callbacks=callbacks,\n",
    "                                      steps_per_epoch=np.ceil(LM_train.shape[0]/batch_size)\n",
    "                                      )         \n",
    "        \n",
    "else:\n",
    "    TrainDataGen = MixupGenerator(LM_train, \n",
    "                                  y_train, \n",
    "                                  batch_size=batch_size,\n",
    "                                  alpha=mixup_alpha,\n",
    "                                  crop_length=crop_length)()\n",
    "\n",
    "    #train the model\n",
    "    if MODE == 'DEV':\n",
    "        history = model.fit_generator(TrainDataGen,\n",
    "                                      validation_data=(LM_val, y_val),\n",
    "                                      epochs=num_epochs, \n",
    "                                      verbose=1, \n",
    "                                      workers=4,\n",
    "                                      max_queue_size = 100,\n",
    "                                      callbacks=callbacks,\n",
    "                                      steps_per_epoch=np.ceil(LM_train.shape[0]/batch_size)\n",
    "                                      ) \n",
    "    elif MODE == 'VAL':\n",
    "        history = model.fit_generator(TrainDataGen,\n",
    "                                      epochs=num_epochs, \n",
    "                                      verbose=1, \n",
    "                                      workers=4,\n",
    "                                      max_queue_size = 100,\n",
    "                                      callbacks=callbacks,\n",
    "                                      steps_per_epoch=np.ceil(LM_train.shape[0]/batch_size)\n",
    "                                      ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(savedir + '/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
